### Introduction
MyCrawler作为个人爬虫项目的记录，基于python和scrapy框架，希望分别对豆瓣，知乎和新浪微博进行爬虫实验，进而了解更多的爬虫技巧和策略

### Progress
目前完成了对豆瓣上电影信息和短评的爬取，简单爬取了热门十部电影的信息和共计一千八百余条短评。
在每部电影前十页短评的基础上，利用了Jieba对评论内容进行了停用词过滤和中文分词，最后用wordcloud生成了简单的词云。
应用了更换UA，代理ip，模拟登录和cookie使用等简单的策略。

### To Do List
之后希望爬取的网站和内容：
知乎：个人信息和用户的关注网络
微博：用户原创微博内容的文本分析

希望应用和实现的爬虫技巧：
对包含js代码网页的处理;
增量爬取的实现;
url的去重算法;
多线程的使用策略和实现;
分布式爬虫;

### Clarification
本人对于爬虫的兴趣主要来源于希望了解更多网页的原理知识和数据处理分析的入门，希望了解如何快速大量的爬取数据，但并不是最终目的，实验过程中也不会恶意访问以上网站。

### Discuss
Email: xzyduoduo@126.com
